import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import optuna
import xgboost as xgb
from sklearn.model_selection import train_test_split
import sklearn.metrics
from functools import partial
import sklearn.datasets
import string
from sklearn import preprocessing
import category_encoders as ce
from sklearn.preprocessing import LabelEncoder


def getTrainingDataForOptuna():
    train_data = pd.read_csv("../input/train.csv", header=0)
    train_data = preprocess2(train_data)
    train_y = pd.DataFrame(train_data['Survived'],columns=['Survived'])
    train_x = train_data.drop(['Survived'], axis=1)
    pre_train_x, pre_test_x, pre_train_y, pre_test_y = train_test_split(train_x, train_y, test_size=0.2, random_state=0)
    return pre_train_x, pre_test_x, pre_train_y, pre_test_y

def getTrainingData():
    train_data = pd.read_csv("../input/train.csv", header=0)
    train_data = preprocess2(train_data)
    train_y = pd.DataFrame(train_data['Survived'],columns=['Survived'])
    train_x = train_data.drop(['Survived'], axis=1)
    return train_x, train_y

def preprocess(df):
    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())
    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['Embarked'] = df['Embarked'].fillna('Unknown')
    df['Embarked'] = df['Embarked'].map({'S':0, 'C':1, 'Q':2, 'Unknown':3}).astype(int)
    df['Sex'] = df['Sex'].apply(lambda x: 1 if x =='male' else 0)
    df['Cabin'] = df['Cabin'].fillna(0)
    df['Cabin'] = df['Cabin'].apply(lambda x: 1 if x !=0 else 0)
    df = df.drop(['Name','PassengerId','Ticket'], axis = 1)
    return df


def preprocess2(df):
    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())
    df['Age'] = df['Age'].fillna(df['Age'].mean())
    df['Embarked'] = df['Embarked'].fillna('Unknown')
    df['Embarked'] = df['Embarked'].map({'S':0, 'C':1, 'Q':2, 'Unknown':3}).astype(int)
    df['Sex'] = df['Sex'].apply(lambda x: 1 if x =='male' else 0)
    df['Cabin'] = df['Cabin'].fillna(0)
    df['Cabin'] = df['Cabin'].apply(lambda x: 1 if x !=0 else 0)
    df['Name'] = convertName(df['Name'])
    df['Ticket'] = convertTicket(df)
    df = df.drop(['PassengerId'], axis = 1)
    return df

def convertName(pd):
    con = []
    for el in pd:
        if el.find('Mr.') >= 0:
            con.append(1)
        elif el.find('Miss.') >= 0:
            con.append(2)
        elif el.find('Mrs.') >= 0:
            con.append(3)
        else:
            con.append(0)
    return con

def convertTicket(pd):
    t_data = pd['Ticket'].apply(lambda x: x.strip('0123456789'))
    t_data = t_data.fillna('None')
    ce_oe = LabelEncoder()
    con = ce_oe.fit_transform(t_data)
    return con


def objective(pre_train_x, pre_train_y, pre_test_x, pre_test_y, trial):
    dtrain = xgb.DMatrix(pre_train_x, label=pre_train_y)
    dtest = xgb.DMatrix(pre_test_x, label=pre_test_y)

    n_round = trial.suggest_int('n_round', 1, 15)
    param = {'verbosity': 0, 'objective': 'binary:logistic',#"tree_method":"gpu_hist",
             'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart'])
             #'n_estimators': trial.suggest_int('n_estimators', 0, 1000),
             }
    if param['booster'] == 'gbtree' or param['booster'] == 'dart':
        param['max_depth'] = trial.suggest_int('max_depth', 1, 40)
        param['eta'] = trial.suggest_loguniform('eta', 1e-8, 1.0)
        param['gamma'] = trial.suggest_loguniform('gamma', 1e-8, 3.0)
        param['grow_policy'] = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])
        param['min_child_weight'] = trial.suggest_int('min_child_weight', 1, 20)
        param['subsample'] = trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)
        param['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)
        param['colsample_bylevel'] = trial.suggest_uniform('colsample_bylevel', 0.1, 0.9)
        param['colsample_bynode'] = trial.suggest_uniform('colsample_bynode', 0.1, 0.9)
        param['max_leaves'] = trial.suggest_int('max_leaves', 0, 100)
        param['alpha'] = trial.suggest_loguniform('alpha', 1e-8, 1.0)
        param['lambda'] = trial.suggest_loguniform('lambda', 1e-8, 1.0)
    if param['booster'] == 'dart':
        param['sample_type'] = trial.suggest_categorical('sample_type', ['uniform', 'weighted'])
        param['normalize_type'] = trial.suggest_categorical('normalize_type', ['tree', 'forest'])
        param['rate_drop'] = trial.suggest_loguniform('rate_drop', 1e-8, 1.0)
        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)

    bst = xgb.train(param, dtrain, n_round)
    preds = bst.predict(dtest)
    pred_labels = np.rint(preds)
    accuracy = sklearn.metrics.accuracy_score(pre_test_y, pred_labels)
    return 1.0 - accuracy


def train(train_x, train_y, param, n_round):
    train = xgb.DMatrix(train_x, label=train_y)
    bst = xgb.train(param, train, n_round)
    return bst

def simpleTrain(train_x, train_y):
    train = xgb.DMatrix(train_x, label=train_y)
    param = {'max_depth':5, 'max_leaves':48, 'num_class':1, 'eta':0.1, 
             'learning_rate':0.3, 'objective':'binary:logistic','silent':True}
    num_round =10
    bst = xgb.train(param, train, num_round)
    return bst

def outValConverter(prediction):
    con_pre = []
    for el in prediction:
        if el > 0.5:
            con_pre.append(1)
        else:
            con_pre.append(0)
    return con_pre


def generateSubmission(prediction_pd):
    df_out = pd.read_csv("../input/test.csv",header=0)
    df_out = df_out['PassengerId']
    out = prediction_pd["Survived"]
    submission = pd.DataFrame({"PassengerId": df_out, "Survived": out})
    submission.to_csv('gender_submission.csv', index=False)
    print(submission)


#use optuna, 0.76555
pre_train_x, pre_test_x, pre_train_y, pre_test_y = getTrainingDataForOptuna()
study = optuna.create_study()
f = partial(objective, pre_train_x.values, pre_train_y.values, pre_test_x.values, pre_test_y.values)
study.optimize(f, n_trials=300)
train_x, train_y = getTrainingData()
bst = train(train_x, train_y, study.best_params, study.best_params['n_round'])


#not use optuna, 0.77033
# train_x, train_y = getTrainingData()
# bst = simpleTrain(train_x, train_y)

test_data = pd.read_csv("../input/test.csv", header=0)
prediction = bst.predict(xgb.DMatrix(preprocess2(test_data)))
outputs = pd.DataFrame(outValConverter(prediction), columns=['Survived'])
generateSubmission(outputs)
print('Completed')
